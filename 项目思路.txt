一、 数据清理
	1. 找出所有存在异常值的列
		- describe()方法
		- info()方法
		- 通过pandas条件筛选出异常值
		- 通过图表的形式查看所有的异常值存在点 
	2. 处理异常值
		(1) 将无用的数据行直接删除
		(2)	填充异常值
			- 把所有异常值都赋值为Nan
			- 通过fillna方法，对不同的列按照不同策略进行填充：
				- 离散型变量： 使用转义中位数进行填充
				- 连续型变量： 使用平均值或者0进行填充
	3. 去掉无用的列
		- 如果某一属性列的值过于少，那么就可以舍去该属性列
		- 查看相关性
			- 如果属性的列与预测的目标(标签)相关性不大，那么也可以舍去该列


二、数据分析与列的处理
	1. 将每一列数据和happiness进行可视化
	2. 分析可视化图表结果包含的意义
	3. 如果数据存在某些自然因素（比如：数据量太小）
		- 对数据列进行重分类
			- 将数据量的少的类别归为一类，或者是归为其他的类别当中去
	4. 总结出一些重要的影响因素
	
	
	
	 
三、特征工程
	1. 对特征列进行扩展和删除
		(1)特征组合
			- 将重要的特征直接进行笛卡尔积相乘组合；
			- 特征列去重；
		(2)特征列的筛选
			- 使用基于随机森林的嵌入法来计算特征额重要程度，
				去除相关性较弱的特征
			- 
		(3)更新特征列
		
		
四、建模评分
	1. 首先对多种模型都进行训练，找出最优的模型
		- 评判标准：
			- scoring="neg_mean_squared_error"
	2. 基于相对较优的模型开始进行参数调整
		调整方式：
			- 使用GridSearchCV接口进行最优参数查询
				 - 每次指定想要调优的参数，给定范围
				 - 开始训练
				 - 通过参数
					- best_params_：dict 获取最佳参数的组合
					- best_score_： float64 获取此种情况的得分(这里指定了scoring='neg_mean_squared_error')
	3.  确定最终参数组合，开始模型训练
	4.  根据根据测试集，对训练的模型进行预测
	5.  提交结果
		
	